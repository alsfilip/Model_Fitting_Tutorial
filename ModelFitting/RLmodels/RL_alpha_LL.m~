function data = RL_alpha_LL(rew,alpha,beta,choices)

%% INITIALIZE ARRAYS
ntrials = length(rew(:,1));  %Number of trials
V = NaN(ntrials,2);          %Q-values at the start of each trial
Vinit = [.5 .5];             %Initial Q-values
Pchoice = NaN(ntrials,2);    %Probability of making each choice on each trial
Choice = ones(ntrials,1);    %Stochastic choice made for a given simulation
Delta = NaN(ntrials,1);      %Reward prediction error

%% RUN MODEL
for i = 1:ntrials
    if i == 1
        V(i,:) = Vinit;
    end
    
    % Get probability of making a choice given the current Q-values
    Pchoice(i,:) = exp(beta.*V(i,:))./sum(exp(beta.*V(i,:)));
 
    % Make choice - 1 for left 2 for right
    if rand < Pchoice(i,2)
        Choice(i) = 2;
    end
    
    % Get reward prediction error (delta)
    reward = rew(i,Choice(i));
    Delta(i) = reward-V(i,Choice(i));
    
    %Update Q-value for the next trial
    if i < ntrials
        V(i+1,:) = V(i,:);
        V(i+1,Choice(i)) = V(i,Choice(i))+(alpha*Delta(i));
    end
end

%% SAVE ARRAYS
data.ParamNames = {'Alpha','Beta'};
data.ParamValues = [alpha,beta];
data.QValues = V;
data.Pchoice = Pchoice;
data.Choices = Choice;
data.Delta = Delta;
data.reward = rew;
end
    